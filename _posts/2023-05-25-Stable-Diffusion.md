# Stable Diffusion

Whilst looking at the CIFAKE data and learning about what it was, I learnt that the fake images in the dataset were generated by Stable Diffusion. I previously used Stable Diffusion on my own computer and found this topic very interesting. One thing that I have noticed is that the images produced by Stable Diffusion have a lot of abnormalities and artefacts in the generated images. Things like extra limbs, disfigured faces, unnatural landscapes, no shadows, poor reflections were very common in the generated images of the base stable diffusion model. A lot of examples shown online of AI-generated images also tend to be of very simple objects or design. Things like 'pink elephant weaing a hat on the moon' show the imaginative performance of the model but don't show the actual capabilties of the model. 

Using the base Stable Diffusion model also results in the worse-quality results. They do not look that good and there are abnormalities in pretty much every image generated. It is obvious that each image generated is AI-generated. Here some examples of some scenes that Stable Diffusion produces:

![sd](https://github.com/Benjamin-Guy/Benjamin-Guy.github.io/assets/132412391/08030cca-650b-4532-9090-a676748a4dbe)

A significant increase in quality comes from using Stable Diffusion checkpoint mergers to merge different models that achieve significantly better results. In addition to this, textual inversions and negative prompting can be used to fine-tune and ensure realistic image generations. Proper prompting skills can also result in significantly better looking images. Here are some of the images that I have generated using these methods using the same prompt as the one used on the base stable diffusion model:

![o](https://github.com/Benjamin-Guy/Benjamin-Guy.github.io/assets/132412391/bf33f9e3-33b9-4d3a-b031-2b0a14cd327e)

It is quite clear to see that the base stable diffusion model is incapable of producing a realistic scene, whereas the merged model using various textual inversions, negative prompts, LORAs and fine-tuned sampling methods achieved much better and more believeable results.
